<h1 align="center">Awesome Story Visualization</h1>

A curated list of resources, papers, and benchmarks focused on **Story Visualization**.

Entries are sorted by date (newest first).

If you want to contribute, please edit the `citations.json` file, run the generator script, and create a pull request.

If you are looking for Storytelling, text based, take a look at [Awesome-Story-Generation](https://github.com/yingpengma/Awesome-Story-Generation).

---

## Papers

- **[StoryCrafter: Instance-Aligned Multi-Character Storytelling with Diffusion Policy Learning](https://dl.acm.org/doi/10.1145/3746027.3755022)** `MM 2025`  <br> _Keywords: Image_
- **[Enabling Dynamic Storytelling via Training-Free Multimodal Synchronized Video Synthesis with Character Consistency](https://dl.acm.org/doi/10.1145/3728422.3762146)** `LGM3A 2025`  <br> _Keywords: Video_
- **[HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video Narratives](https://arxiv.org/abs/2510.20822)** `arXiv` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2510.20822) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/yihao-meng/HoloCine) <br> _Keywords: Video_
- **[AniME: Adaptive Multi-Agent Planning for Long Animation Generation](https://arxiv.org/abs/2508.18781)** `arXiv` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2508.18781) <br> _Keywords: Image, Video, Audio, Agentic_
- **[Co-Story: Consistent, Training-Free Story Visualization Using Latent Diffusion and ControlNet](https://www.researchgate.net/publication/396752085_Co-Story_Consistent_Training-Free_Story_Visualization_Using_Latent_Diffusion_and_ControlNet)** `MIUCC 2025`  <br> _Keywords: Image_
- **[Story2Board: A Training-Free Approach for Expressive Storyboard Generation](https://arxiv.org/abs/2508.09983)** `arXiv` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2508.09983) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/DavidDinkevich/Story2Board) <br> _Keywords: Image_
- **[A Survey on Long-Video Storytelling Generation: Architectures, Consistency, and Cinematic Quality](https://arxiv.org/abs/2507.07202)** `ICCV Workshop 2025` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2507.07202) <br> _Keywords: Survey_
- **[AgentStory: A Multi-Agent System for Story Visualization with Multi-Subject Consistent Text-to-Image Generation](https://dl.acm.org/doi/10.1145/3731715.3733271)** `ICMR 2025` [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/tc2000731/AgentStory) <br> _Keywords: Image, Agentic_
- **[Audit & Repair: An Agentic Framework for Consistent Story Visualization in Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.18900)** `arXiv` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2506.18900) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://auditandrepair.github.io/) <br> _Keywords: Image, Agentic_
- **[AniMaker: Multi-Agent Animated Storytelling with MCTS-Driven Clip Generation](https://arxiv.org/abs/2506.10540)** `arXiv` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2506.10540) <br> _Keywords: Image, Video, Audio, Agentic_
- **[Action2Dialogue: Generating Character-Centric Narratives from Scene-Level Prompts](https://arxiv.org/abs/2505.16819v3)** `arXiv` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2505.16819v3) <br> _Keywords: Video_
- **[STORYANCHORS: Generating Consistent Multi-Scene Story Frames for Long-Form Narratives](https://arxiv.org/abs/2505.08350)** `arXiv` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2505.08350) <br> _Keywords: Image, Video_
- **[AnimeGamer: Infinite Anime Life Simulation with Next Game State Prediction](https://arxiv.org/abs/2504.01014)** `ICCV 2025` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2504.01014) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/TencentARC/AnimeGamer) <br> _Keywords: Video_
- **[MM-StoryAgent: Immersive Narrated Storybook Video Generation with a Multi-Agent Paradigm across Text, Image and Audio](https://arxiv.org/abs/2503.05242)** `arXiv` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2503.05242) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/X-PLUG/MM_StoryAgent) <br> _Keywords: Image, Video, Audio, Agentic_
- **[VisAgent: Narrative-Preserving Story Visualization Framework](https://arxiv.org/abs/2503.02399)** `arXiv` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2503.02399) <br> _Keywords: Image, Agentic_
- **[VideoAuteur: Towards Long Narrative Video Generation](https://arxiv.org/abs/2501.06173)** `ICCV 2025` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2501.06173) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://videoauteur.github.io/VideoDirectorGPT - Consistent Multi-Scene Video Generation via LLM Guided Planning) <br> _Keywords: Video_
- **[DiffSensei: Bridging Multi-Modal LLMs and Diffusion Models for Customized Manga Generation](https://arxiv.org/abs/2412.07589)** `CVPR 2025` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2412.07589) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/jianzongwu/DiffSensei?tab=readme-ov-file) <br> _Keywords: Image, Manga_
- **[StoryWeaver: A Unified World Model for Knowledge-Enhanced Story Character Customization](https://arxiv.org/abs/2412.07375)** `AAAI 2025` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2412.07375) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/Aria-Zhangjl/StoryWeaver) <br> _Keywords: Image_
- **[Mind the Time: Temporally-Controlled Multi-Event Video Generation](https://arxiv.org/abs/2412.05263)** `CVPR 2025` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2412.05263) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://mint-video.github.io/)
- **[StoryAgent: Customized Storytelling Video Generation via Multi-Agent Collaboration](https://arxiv.org/abs/2411.04925)** `arXiv` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2411.04925) <br> _Keywords: Image, Agentic_
- **[KAHANI: Culturally-Nuanced Visual Storytelling Tool for Non-Western Cultures](https://arxiv.org/abs/2410.19419)** `arXiv` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2410.19419) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/microsoft/Kahani?tab=readme-ov-file) <br> _Keywords: Image_
- **[Story-Adapter: A Training-free Iterative Framework for Long Story Visualization](https://arxiv.org/abs/2410.06244)** `arXiv` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2410.06244) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/UCSC-VLAA/story-adapter) <br> _Keywords: Image_
- **[MovieDreamer: Hierarchical Generation for Coherent Long Visual Sequence](https://arxiv.org/abs/2407.16655)** `ICLR 2025` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2407.16655) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/aim-uofa/MovieDreamer) <br> _Keywords: Video, Audio_
- **[DreamStory: Open-Domain Story Visualization by LLM-Guided Multi-Subject Consistent Diffusion](https://arxiv.org/abs/2407.12899)** `arXiv` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2407.12899) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/hehuiguo/DreamStory) <br> _Keywords: Image_
- **[ContextualStory: Consistent Visual Storytelling with Spatially-Enhanced and Storyline Context](https://arxiv.org/abs/2407.09774)** `AAAI 2025` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2407.09774) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/sixiaozheng/ContextualStory) <br> _Keywords: Image_
- **[SEED-Story: Multimodal Long Story Generation with Large Language Model](https://arxiv.org/abs/2407.08683)** `ICCV Workshop 2025` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2407.08683) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/TencentARC/SEED-Story) <br> _Keywords: Image_
- **[StoryDiffusion: How to Support UX Storyboarding With Generative-AI](https://arxiv.org/abs/2407.07672)** `ICMI 2025` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2407.07672) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](github)
- **[Boosting Consistency in Story Visualization with Rich-Contextual Conditional Diffusion Models](https://arxiv.org/abs/2407.02482)** `AAAI 2025` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2407.02482) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/muzishen/RCDMs) <br> _Keywords: Image_
- **[StoryImager: A Unified and Efficient Framework for Coherent Story Visualization and Completion](https://arxiv.org/abs/2404.05979)** `ECCV 2024` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2404.05979) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/tobran/StoryImager) <br> _Keywords: Image_
- **[Masked Generative Story Transformer with Character Guidance and Caption Augmentation](https://arxiv.org/abs/2403.08502)** `venue` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2403.08502) <br> _Keywords: Image_
- **[AesopAgent: Agent-driven Evolutionary System on Story-to-Video Production](https://arxiv.org/abs/2403.07952)** `arXiv` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2403.07952) <br> _Keywords: Image, Video, Agentic_
- **[StoryGPT-V: Large Language Models as Consistent Story Visualizers](https://arxiv.org/abs/2312.02252)** `CVPR 2025` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2312.02252) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](github) <br> _Keywords: Image_
- **[AutoStory: Generating Diverse Storytelling Images with Minimal Human Effort](https://arxiv.org/abs/2311.11243)** `IJCV 2024` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2311.11243) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/aim-uofa/AutoStory) <br> _Keywords: Image_
- **[VideoDirectorGPT - Consistent Multi-Scene Video Generation via LLM Guided Planning](https://arxiv.org/abs/2309.15091)** `COLM 2024` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2309.15091) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/HL-hanlin/VideoDirectorGPT) <br> _Keywords: Video_
- **[Story Visualization by Online Text Augmentation with Context Memory](https://arxiv.org/abs/2308.07575)** `ICCV 2023` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2308.07575) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/yonseivnl/cmota) <br> _Keywords: Image_
- **[Intelligent Grimm -- Open-ended Visual Storytelling via Latent Diffusion Models](https://arxiv.org/abs/2306.00973)** `CVPR 2024` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2306.00973) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/haoningwu3639/StoryGen) <br> _Keywords: Image_
- **[Make-A-Story: Visual Memory Conditioned Consistent Story Generation](https://arxiv.org/abs/2211.13319)** `CVPR 2023` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2211.13319) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/ubc-vision/Make-A-Story) <br> _Keywords: Image_
- **[Synthesizing Coherent Story with Auto-Regressive Latent Diffusion Models](https://arxiv.org/abs/2211.10950)** `WACV 2024` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2211.10950) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/xichenpan/ARLDM) <br> _Keywords: Image_
- **[StoryDALL-E: Adapting Pretrained Text-to-Image Transformers for Story Continuation](https://arxiv.org/abs/2209.06192)** `ECCV 2022` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2209.06192) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/adymaharana/storydalle) <br> _Keywords: Image_
- **[StoryGAN: A Sequential Conditional GAN for Story Visualization](https://arxiv.org/abs/1812.02784)** `CVPR 2019` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/1812.02784) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/yitong91/StoryGAN) <br> _Keywords: Image, GAN, Sequential Generation_

## Benchmarks

- **[ViStoryBench: Comprehensive Benchmark Suite for Story Visualization](https://arxiv.org/abs/2505.24862)** `arXiv` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2505.24862) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://github.com/vistorybench/vistorybench?tab=readme-ov-file) <br> _Keywords: Image, Character consistency_

## Datasets

- **[MovieBench: A Hierarchical Movie Level Dataset for Long Video Generation](https://arxiv.org/abs/2411.15262)** `CVPR 2025` [![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2411.15262) [![GitHub](https://img.shields.io/badge/GitHub-Repo-181717.svg?logo=github)](https://arxiv.org/abs/2411.15262) <br> _Keywords: Video_
